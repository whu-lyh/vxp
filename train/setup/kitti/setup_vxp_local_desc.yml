general:
  ## ====== Modify only this section ======
  train_pickle_dir: <path/to/{name}_training_pair_3d_student_p10_n25.pickle>
  val_pickle_dir: <path/to/{name}_testing_pair_3d_student_p10_n25.pickle>
  annotation_dir: <path/to/kitti/all_annotation.csv>
  save_dir: <path/to/save_dir/kitti>
  name: vxp_vpenc_kitti ## name of the model
  ## ======================================
model:
  ## ====== Modify only this section ======
  teacher_setup: <path/to/setup_vxp_imgnetwork_kitti_YYYY_MM_DD_HH_mm_ss.yml>
  teacher_model: <path/to/vxp_imgnetwork_kitti_YYYY_MM_DD_HH_mm_ss.pth>
  ## ======================================
  teacher_desc_type: output
  arch: VoxelLocalFeatureExtractor
  ## The below parameters shouldn't be changed
  parameters:
    grid_zyx: null
    voxel_size: null
    pcd_range: null
    vfe_feat_channels: [16, 64, 128]
    middle_spconv_in_channels: 128
    # middle_spconv_out_channels: 512
    middle_spconv_out_channels: 384
    middle_base_channels: 16
    middle_encoder_channels: !!python/tuple
      - !!python/tuple [16]
      - !!python/tuple [32, 64, 64]
      - !!python/tuple [128, 256, 256]
    middle_encoder_paddings: !!python/tuple
      - !!python/tuple
        - !!python/tuple [1, 1, 1] ## First stage first layer would be submanifold convolution
      - !!python/tuple
        - !!python/tuple [1, 1, 1] ## First layer would be spconv
        - !!python/tuple [1, 1, 1] ## Submanifold convolution
        - !!python/tuple [1, 1, 1] ## Submanifold convolution
      - !!python/tuple
        - !!python/tuple [1, 1, 1] ## First layer would be spconv
        - !!python/tuple [1, 1, 1] ## Submanifold convolution
        - !!python/tuple [1, 1, 1] ## Submanifold convolution
    middle_encoder_downsampling_other_dim: [False, True, False]
  ## please give the normalized intrisics and possible axes alignment
  proj_params:
    fx: 0.58141637
    fy: 1.9189833
    cx: 0.491184
    cy: 0.4597181
    R: [[0, -1, 0], [0, 0, -1], [1, 0, 0]]
    h: 28 ## Output height of the feature map
    w: 28 ## Output width of the feature map
    # h: 15 ## Output height of the feature map
    # w: 45 ## Output width of the feature map
dataset:
  rebase_dir: null
  batch_size: 8
  num_workers: 8
  voxelization: True
  random_horizontal_mirroring_p: 0.5
  ## This has to be modify to make sure that the input point cloud map is described in the camera cooraindate frame
  ## and the z-axis upward, x-axis forward
  pcd_coordinate_transformation:
    ## Note that if OnlinePointAffineTransformation is not needed, please remove it to speed up data processing
    OnlinePointAffineTransformation:
      parameters:
        {
          x_axis: [2.34773604e-04, 1.04494081e-02, 9.99945368e-01],
          y_axis: [-9.99944129e-01, 1.05653538e-02, 1.24365346e-04],
          z_axis: [-1.05634776e-02, -9.99889606e-01, 1.04513032e-02],
          trans: [5.70524492e-02, -7.54667181e-02, -2.69386924e-01],
        }
    OnlineRotZ:
      parameters:
        angle: 90
        use_degree: true
    OnlineRotX:
      parameters:
        angle: 90
        use_degree: true
  pcd_preprocessing:
    OnlineVoxelization:
      ## The parameter for voxeliation are not expected to be changed, if changes are needed, make sure that the output grid size is 110 x 110 x 110
      parameters:
        {
          point_cloud_range: [0, -22, -4, 44, 22, 18],
          max_num_points: 35,
          voxel_size: [0.4, 0.4, 0.2],
          max_voxels: 10000,
        }
      # parameters: {point_cloud_range: [0, -20, -2.5, 50, 20, 15], max_num_points: 35, voxel_size: [0.75, 0.2, 0.0875], max_voxels: 10000} ## grid size 67 x 200 x 200
  pcd_data_augmentation:
    {}
    # DataAugmentationRandomRigidBodyTransformation:
    #   parameters:
    #     {
    #       x_limit: 1.5,
    #       y_limit: 1.5,
    #       z_limit: 1.5,
    #       pitch_limit: 2,
    #       yaw_limit: 10,
    #       roll_limit: 2,
    #     }
  img_data_augmentation:
    ColorJitter:
      parameters: { brightness: 0.1, contrast: 0.1, saturation: 0.1, hue: 0.1 }
    # RandomAffine:
    #   parameters: { degrees: [-5, 5], translate: [0.1, 0.1] }
loss:
  fn: SmoothL1Loss ## MSELoss
  parameters: { reduction: "none" }
  inv_depth_weighted_loss: True

optimizer:
  fn: Adam
  parameters:
    lr: 1.0e-04
    weight_decay: 1.0e-06
  epochs: 30
  min_lr: 5.0e-06

scheduler:
  fn: LambdaLR
  parameters: { step_size: 2, gamma: 0.95 }
